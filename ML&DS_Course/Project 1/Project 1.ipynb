{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea35389",
   "metadata": {},
   "source": [
    "# Heart Disease Project\n",
    "\n",
    "**Column Descriptions**\n",
    "\n",
    "* age - age in years\n",
    "* sex - (1 = male; 0 = female)\n",
    "* cp - chest pain type\n",
    "    * 0: Typical angina: chest pain related decrease blood supply to the heart\n",
    "    * 1: Atypical angina: chest pain not related to heart\n",
    "    * 2: Non-anginal pain: typically esophageal spasms (non heart related)\n",
    "    * 3: Asymptomatic: chest pain not showing signs of disease\n",
    "* trestbps - resting blood pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern\n",
    "* chol - serum cholestoral in mg/dl\n",
    "    * serum = LDL + HDL + .2 * triglycerides\n",
    "    * above 200 is cause for concern\n",
    "* fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "    * '>126' mg/dL signals diabetes\n",
    "* restecg - resting electrocardiographic results\n",
    "    * 0: Nothing to note\n",
    "    * 1: ST-T Wave abnormality\n",
    "        * can range from mild symptoms to severe problems\n",
    "        * signals non-normal heart beat\n",
    "    * 2: Possible or definite left ventricular hypertrophy\n",
    "        * Enlarged heart's main pumping chamber\n",
    "* thalach - maximum heart rate achieved\n",
    "* exang - exercise induced angina (1 = yes; 0 = no)\n",
    "* oldpeak - ST depression induced by exercise relative to rest looks at stress of heart during excercise unhealthy heart will stress more\n",
    "* slope - the slope of the peak exercise ST segment\n",
    "    * 0: Upsloping: better heart rate with excercise (uncommon)\n",
    "    * 1: Flatsloping: minimal change (typical healthy heart)\n",
    "    * 2: Downslopins: signs of unhealthy heart\n",
    "* ca - number of major vessels (0-3) colored by flourosopy\n",
    "    * colored vessel means the doctor can see the blood passing through\n",
    "    * the more blood movement the better (no clots)\n",
    "* thal - thalium stress result\n",
    "    * 1,3: normal\n",
    "    * 6: fixed defect: used to be defect but ok now\n",
    "    * 7: reversable defect: no proper blood movement when excercising\n",
    "* target - have disease or not (1=yes, 0=no) (= the predicted attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcefc3e",
   "metadata": {},
   "source": [
    "### Importing Modules and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6f421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Basic Modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing Magical Functions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing Various Estimators\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Importing Required Models for Evaluation\n",
    "from sklearn.model_selection import train_test_split , cross_val_score , RandomizedSearchCV , GridSearchCV\n",
    "from sklearn.metrics import accuracy_score , precision_score , recall_score , f1_score , classification_report , confusion_matrix , RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7c79a",
   "metadata": {},
   "source": [
    "### Importing the Heart Disease CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef7c9e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the CSV File\n",
    "\n",
    "heart=pd.read_csv(\"heart-disease.csv\")\n",
    "heart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6e295",
   "metadata": {},
   "source": [
    "### Details About the Heart Disease CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8b0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "# About this CSV File\n",
    "\n",
    "heart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c836b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# About this CSV File\n",
    "\n",
    "heart.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ed8313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding Missing Values\n",
    "\n",
    "heart.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fcfcd7",
   "metadata": {},
   "source": [
    "### Heart Disease Frequency among various Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1defeaf",
   "metadata": {},
   "source": [
    "#### 1 . Sex Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df89b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sex\n",
       " 1    207\n",
       " 0     96\n",
       " Name: count, dtype: int64,\n",
       " target\n",
       " 1    165\n",
       " 0    138\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Heart Disease Frequency based on Sex\n",
    "\n",
    "heart[\"sex\"].value_counts() , heart[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71c7726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target    0   1\n",
       "sex            \n",
       "0        24  72\n",
       "1       114  93"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sex vs Target\n",
    "\n",
    "pd.crosstab(heart[\"sex\"],heart[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c5ccfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Sex vs Target\n",
    "\n",
    "pd.crosstab(heart[\"sex\"],heart[\"target\"]).plot(kind=\"bar\");\n",
    "plt.xlabel(\"\");\n",
    "plt.ylabel(\"No. of Heart Disease Patients\");\n",
    "plt.title(\"Heart Disease - Sex Vs Target\");\n",
    "plt.legend([\"Male\" , \"Female\"]);\n",
    "plt.xticks([0,1],[\"No Heart Disease\" , \"Heart Disease\"],rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c84275",
   "metadata": {},
   "source": [
    "#### 2 . Age and Heart Rate Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bbb6b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(age\n",
       " 58    19\n",
       " 57    17\n",
       " 54    16\n",
       " 59    14\n",
       " 52    13\n",
       " 51    12\n",
       " 62    11\n",
       " 60    11\n",
       " 44    11\n",
       " 56    11\n",
       " 64    10\n",
       " 41    10\n",
       " 63     9\n",
       " 67     9\n",
       " 65     8\n",
       " 43     8\n",
       " 45     8\n",
       " 55     8\n",
       " 42     8\n",
       " 61     8\n",
       " 53     8\n",
       " 46     7\n",
       " 48     7\n",
       " 66     7\n",
       " 50     7\n",
       " 49     5\n",
       " 47     5\n",
       " 70     4\n",
       " 39     4\n",
       " 35     4\n",
       " 68     4\n",
       " 38     3\n",
       " 71     3\n",
       " 40     3\n",
       " 69     3\n",
       " 34     2\n",
       " 37     2\n",
       " 29     1\n",
       " 74     1\n",
       " 76     1\n",
       " 77     1\n",
       " Name: count, dtype: int64,\n",
       " <bound method IndexOpsMixin.value_counts of 0      150\n",
       " 1      187\n",
       " 2      172\n",
       " 3      178\n",
       " 4      163\n",
       "       ... \n",
       " 298    123\n",
       " 299    132\n",
       " 300    141\n",
       " 301    115\n",
       " 302    174\n",
       " Name: thalach, Length: 303, dtype: int64>,\n",
       " target\n",
       " 1    165\n",
       " 0    138\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Heart Disease Frequency based on Age and Heart Rate\n",
    "\n",
    "heart[\"age\"].value_counts() , heart[\"thalach\"].value_counts , heart[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d19991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Age and Heart Rate vs Target\n",
    "\n",
    "# Scatter Plot for Heart Disease\n",
    "plt.scatter(heart.age[heart.target==1] , heart.thalach[heart.target==1])\n",
    "\n",
    "# Scatter Plot for Not Heart Disease\n",
    "plt.scatter(heart.age[heart.target==0] , heart.thalach[heart.target==0])\n",
    "\n",
    "# Plotting Additional Information\n",
    "plt.xlabel(\"Age\");\n",
    "plt.ylabel(\"Heart Rate\");\n",
    "plt.title(\"Heart Disease - Age and Heart Rate Vs Target\");\n",
    "plt.legend([\"Heart Disease\" , \"Not Heart Disease\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c62f3e",
   "metadata": {},
   "source": [
    "#### 3 . Chest Pain Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2067115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cp\n",
       " 0    143\n",
       " 2     87\n",
       " 1     50\n",
       " 3     23\n",
       " Name: count, dtype: int64,\n",
       " target\n",
       " 1    165\n",
       " 0    138\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Heart Disease Frequency based on Chest Pain\n",
    "\n",
    "heart[\"cp\"].value_counts() , heart[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71104bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target    0   1\n",
       "cp             \n",
       "0       104  39\n",
       "1         9  41\n",
       "2        18  69\n",
       "3         7  16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chest Pain vs Target\n",
    "\n",
    "pd.crosstab(heart[\"cp\"],heart[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94501120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Chest Pain vs Target\n",
    "\n",
    "pd.crosstab(heart[\"cp\"],heart[\"target\"]).plot(kind=\"bar\");\n",
    "plt.xlabel(\"Chest Pain Type\");\n",
    "plt.ylabel(\"No. of Heart Disease Patients\");\n",
    "plt.title(\"Heart Disease - Chest Pain Vs Target\");\n",
    "plt.legend([\"No Heart Disease\" , \"Heart Disease\"]);\n",
    "plt.xticks([0,1,2,3],[\"Typical Angina\" , \"Atypical Angina\" , \"Non-Anginal Pain\" , \"Asymptomatic\"],rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ae682-fd87-4d3c-9aef-cc5aefb83ee8",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3444dbc1-d623-4638-8c59-4e0affb7f9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098447</td>\n",
       "      <td>-0.068653</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>0.213678</td>\n",
       "      <td>0.121308</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.210013</td>\n",
       "      <td>-0.168814</td>\n",
       "      <td>0.276326</td>\n",
       "      <td>0.068001</td>\n",
       "      <td>-0.225439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.098447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.049353</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>-0.197912</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>-0.280937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>-0.068653</td>\n",
       "      <td>-0.049353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>-0.394280</td>\n",
       "      <td>-0.149230</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.181053</td>\n",
       "      <td>-0.161736</td>\n",
       "      <td>0.433798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>0.279351</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123174</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>-0.121475</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>-0.144931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.213678</td>\n",
       "      <td>-0.197912</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.123174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>-0.151040</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>-0.085239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0.121308</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.137979</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>-0.028046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>-0.151040</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>-0.058770</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>-0.072042</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>0.137230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>-0.398522</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>-0.344187</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.421741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>-0.394280</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>-0.257748</td>\n",
       "      <td>0.115739</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>-0.436757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.210013</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>-0.149230</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>-0.058770</td>\n",
       "      <td>-0.344187</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.577537</td>\n",
       "      <td>0.222682</td>\n",
       "      <td>0.210244</td>\n",
       "      <td>-0.430696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>-0.168814</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.121475</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.257748</td>\n",
       "      <td>-0.577537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080155</td>\n",
       "      <td>-0.104764</td>\n",
       "      <td>0.345877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.276326</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>-0.181053</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.137979</td>\n",
       "      <td>-0.072042</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>0.115739</td>\n",
       "      <td>0.222682</td>\n",
       "      <td>-0.080155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>-0.391724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>0.068001</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>-0.161736</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>0.210244</td>\n",
       "      <td>-0.104764</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.344029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.225439</td>\n",
       "      <td>-0.280937</td>\n",
       "      <td>0.433798</td>\n",
       "      <td>-0.144931</td>\n",
       "      <td>-0.085239</td>\n",
       "      <td>-0.028046</td>\n",
       "      <td>0.137230</td>\n",
       "      <td>0.421741</td>\n",
       "      <td>-0.436757</td>\n",
       "      <td>-0.430696</td>\n",
       "      <td>0.345877</td>\n",
       "      <td>-0.391724</td>\n",
       "      <td>-0.344029</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       sex        cp  trestbps      chol       fbs  \\\n",
       "age       1.000000 -0.098447 -0.068653  0.279351  0.213678  0.121308   \n",
       "sex      -0.098447  1.000000 -0.049353 -0.056769 -0.197912  0.045032   \n",
       "cp       -0.068653 -0.049353  1.000000  0.047608 -0.076904  0.094444   \n",
       "trestbps  0.279351 -0.056769  0.047608  1.000000  0.123174  0.177531   \n",
       "chol      0.213678 -0.197912 -0.076904  0.123174  1.000000  0.013294   \n",
       "fbs       0.121308  0.045032  0.094444  0.177531  0.013294  1.000000   \n",
       "restecg  -0.116211 -0.058196  0.044421 -0.114103 -0.151040 -0.084189   \n",
       "thalach  -0.398522 -0.044020  0.295762 -0.046698 -0.009940 -0.008567   \n",
       "exang     0.096801  0.141664 -0.394280  0.067616  0.067023  0.025665   \n",
       "oldpeak   0.210013  0.096093 -0.149230  0.193216  0.053952  0.005747   \n",
       "slope    -0.168814 -0.030711  0.119717 -0.121475 -0.004038 -0.059894   \n",
       "ca        0.276326  0.118261 -0.181053  0.101389  0.070511  0.137979   \n",
       "thal      0.068001  0.210041 -0.161736  0.062210  0.098803 -0.032019   \n",
       "target   -0.225439 -0.280937  0.433798 -0.144931 -0.085239 -0.028046   \n",
       "\n",
       "           restecg   thalach     exang   oldpeak     slope        ca  \\\n",
       "age      -0.116211 -0.398522  0.096801  0.210013 -0.168814  0.276326   \n",
       "sex      -0.058196 -0.044020  0.141664  0.096093 -0.030711  0.118261   \n",
       "cp        0.044421  0.295762 -0.394280 -0.149230  0.119717 -0.181053   \n",
       "trestbps -0.114103 -0.046698  0.067616  0.193216 -0.121475  0.101389   \n",
       "chol     -0.151040 -0.009940  0.067023  0.053952 -0.004038  0.070511   \n",
       "fbs      -0.084189 -0.008567  0.025665  0.005747 -0.059894  0.137979   \n",
       "restecg   1.000000  0.044123 -0.070733 -0.058770  0.093045 -0.072042   \n",
       "thalach   0.044123  1.000000 -0.378812 -0.344187  0.386784 -0.213177   \n",
       "exang    -0.070733 -0.378812  1.000000  0.288223 -0.257748  0.115739   \n",
       "oldpeak  -0.058770 -0.344187  0.288223  1.000000 -0.577537  0.222682   \n",
       "slope     0.093045  0.386784 -0.257748 -0.577537  1.000000 -0.080155   \n",
       "ca       -0.072042 -0.213177  0.115739  0.222682 -0.080155  1.000000   \n",
       "thal     -0.011981 -0.096439  0.206754  0.210244 -0.104764  0.151832   \n",
       "target    0.137230  0.421741 -0.436757 -0.430696  0.345877 -0.391724   \n",
       "\n",
       "              thal    target  \n",
       "age       0.068001 -0.225439  \n",
       "sex       0.210041 -0.280937  \n",
       "cp       -0.161736  0.433798  \n",
       "trestbps  0.062210 -0.144931  \n",
       "chol      0.098803 -0.085239  \n",
       "fbs      -0.032019 -0.028046  \n",
       "restecg  -0.011981  0.137230  \n",
       "thalach  -0.096439  0.421741  \n",
       "exang     0.206754 -0.436757  \n",
       "oldpeak   0.210244 -0.430696  \n",
       "slope    -0.104764  0.345877  \n",
       "ca        0.151832 -0.391724  \n",
       "thal      1.000000 -0.344029  \n",
       "target   -0.344029  1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "heart.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70ea8f2b-86c6-4c43-80ea-e4cfa7ec7668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Correction Matrix using Seaborn\n",
    "\n",
    "fig , ax = plt.subplots(figsize=(15,15))\n",
    "ax=sns.heatmap(heart.corr() , annot=True , linewidth=0.5 , fmt=\"0.2f\" , cmap=\"crest\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ddf61",
   "metadata": {},
   "source": [
    "### Getting Our Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe8c393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into X and y\n",
    "\n",
    "X=heart.drop(\"target\",axis=1)\n",
    "y=heart[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb74f0",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b0be8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spling Data into Train and Test Data\n",
    "\n",
    "np.random.seed(30)\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69519b",
   "metadata": {},
   "source": [
    "#### 1 . Logistic Regression - Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81f7031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data\n",
    "\n",
    "np.random.seed(30)\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train , y_train)\n",
    "log_sco=model.score(X_test , y_test)\n",
    "log_sco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdadfb",
   "metadata": {},
   "source": [
    "#### 2 . Linear SCV - Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15a93c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8032786885245902"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data\n",
    "\n",
    "np.random.seed(30)\n",
    "model=LinearSVC()\n",
    "model.fit(X_train , y_train)\n",
    "lin_sco=model.score(X_test , y_test)\n",
    "lin_sco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51afaff",
   "metadata": {},
   "source": [
    "#### 3 . KNeighbours Classifier - Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbcba146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6065573770491803"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data\n",
    "\n",
    "np.random.seed(30)\n",
    "model=KNeighborsClassifier()\n",
    "model.fit(X_train , y_train)\n",
    "kn_sco=model.score(X_test , y_test)\n",
    "kn_sco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08453c1",
   "metadata": {},
   "source": [
    "#### 4 . Random Forest Classifier - Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "343346dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868852459016393"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data\n",
    "\n",
    "np.random.seed(30)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train , y_train)\n",
    "rfc_sco=model.score(X_test , y_test)\n",
    "rfc_sco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd99cfb",
   "metadata": {},
   "source": [
    "#### 5 . Bagging Classifier - Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aa6ed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7049180327868853"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data\n",
    "\n",
    "np.random.seed(30)\n",
    "model=BaggingClassifier()\n",
    "model.fit(X_train , y_train)\n",
    "bag_sco=model.score(X_test , y_test)\n",
    "bag_sco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925e993",
   "metadata": {},
   "source": [
    "#### 6 . Perceptron - Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5163af2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5081967213114754"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data\n",
    "\n",
    "np.random.seed(30)\n",
    "model=Perceptron()\n",
    "model.fit(X_train , y_train)\n",
    "per_sco=model.score(X_test , y_test)\n",
    "per_sco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1920f175",
   "metadata": {},
   "source": [
    "#### 7 .Linear Regression - Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2df1a0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4765800115245449"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data\n",
    "\n",
    "np.random.seed(30)\n",
    "model=LinearRegression()\n",
    "model.fit(X_train , y_train)\n",
    "LinReg_sco=model.score(X_test , y_test)\n",
    "LinReg_sco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ed323",
   "metadata": {},
   "source": [
    "### Comparing All Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fd6bf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 85.25,\n",
       " 'Linear SVC': 80.33,\n",
       " 'KNeighhbours Classifier': 60.66,\n",
       " 'Random Forest Classifier': 78.69,\n",
       " 'Bagging Classifier': 70.49,\n",
       " 'Perceptron': 50.82,\n",
       " 'Linear Regression': 47.66}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dictionary\n",
    "\n",
    "mod_sco={\"Logistic Regression\" : round(log_sco*100,2) , \"Linear SVC\" : round(lin_sco*100,2) , \"KNeighhbours Classifier\" : round(kn_sco*100,2) , \"Random Forest Classifier\" : round(rfc_sco*100,2) , \"Bagging Classifier\" : round(bag_sco*100,2) , \"Perceptron\" : round(per_sco*100,2) , \"Linear Regression\" : round(LinReg_sco*100,2)}\n",
    "mod_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef2a8ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Linear SVC</th>\n",
       "      <th>KNeighhbours Classifier</th>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <th>Perceptron</th>\n",
       "      <th>Linear Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>85.25</td>\n",
       "      <td>80.33</td>\n",
       "      <td>60.66</td>\n",
       "      <td>78.69</td>\n",
       "      <td>70.49</td>\n",
       "      <td>50.82</td>\n",
       "      <td>47.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic Regression  Linear SVC  KNeighhbours Classifier  \\\n",
       "Accuracy                85.25       80.33                    60.66   \n",
       "\n",
       "          Random Forest Classifier  Bagging Classifier  Perceptron  \\\n",
       "Accuracy                     78.69               70.49       50.82   \n",
       "\n",
       "          Linear Regression  \n",
       "Accuracy              47.66  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "\n",
    "mod_sco_df=pd.DataFrame(mod_sco , index=[\"Accuracy\"])\n",
    "mod_sco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32437059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting All Model's Accuracy\n",
    "\n",
    "mod_sco_df.T.plot(kind=\"bar\",cmap=\"coolwarm\",figsize=(20,10));\n",
    "plt.xlabel(\"Models Name\");\n",
    "plt.ylabel(\"Accuracy(%)\");\n",
    "plt.title(\"Various Model's Accuracy\")\n",
    "plt.xticks(rotation=0);\n",
    "plt.legend(\"\");\n",
    "i=0\n",
    "for j in mod_sco.values():\n",
    "    plt.text(i,j,f\"{j}%\",ha=\"center\");\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b7e52",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af9322",
   "metadata": {},
   "source": [
    "#### 1 . Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "858f8abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=100000000000000.0, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=32374575428176.4, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=10481131341546.873, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3393221771895.3296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1098541141987.5573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=355648030622.31213, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=115139539932.6448, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=37275937203.14938, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=12067926406.393265, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3906939937.0546207, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1264855216.855296, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=409491506.2380419, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=132571136.55901109, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=42919342.60128778, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=13894954.943731388, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=4498432.668969444, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1456348.4775012443, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=471486.63634573895, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=152641.79671752366, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=49417.13361323838, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=15998.587196060573, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=5179.4746792312235, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.854 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1676.83293681101, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=542.867543932386, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=175.75106248547965, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=56.898660290183045, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=18.420699693267164, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=5.963623316594637, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.854 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1.9306977288832536, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.875 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.729 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.6250551925273976, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.729 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.20235896477251555, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.673 total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.776 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.06551285568595522, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.633 total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.688 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.021209508879201925, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.653 total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.667 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.006866488450043027, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.673 total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.646 total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.735 total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.002222996482526191, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.673 total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.735 total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.0007196856730011528, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.673 total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.00023299518105153813, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.653 total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.735 total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=7.543120063354608e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.673 total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.735 total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.521 total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.688 total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.688 total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=2.4420530945486548e-05, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.653 total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.562 total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=7.906043210907734e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.653 total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=2.5595479226995334e-06, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.592 total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.633 total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.592 total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=8.286427728546859e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.592 total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.653 total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.592 total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.653 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=2.682695795279738e-07, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.521 total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.521 total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=8.68511373751352e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=2.8117686979742367e-08, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=9.102981779915264e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=2.94705170255181e-09, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=9.540954763499962e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=3.0888435964774974e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.542 total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=liblinear;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.531 total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.542 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.479 total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.854 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1500 fits failed out of a total of 3000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.81819728 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.81394558 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.81819728 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.81403061 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80569728 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80569728 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80569728 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.81403061 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80977891 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.82236395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80569728 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.80986395 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.82627551 0.81386054 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82627551        nan        nan 0.81802721 0.81394558 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.81394558        nan        nan 0.81802721 0.80569728 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82219388        nan        nan 0.81386054 0.83869048 0.82627551\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82644558        nan        nan 0.82636054 0.83044218 0.81802721\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.82227891        nan        nan 0.83061224 0.83061224 0.83061224\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.75238095        nan        nan 0.82253401 0.82253401 0.82253401\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.69438776        nan        nan 0.76879252 0.77295918 0.78511905\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.69846939        nan        nan 0.73554422 0.75629252 0.75629252\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.64013605        nan        nan 0.71488095 0.72321429 0.72321429\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.71079932 0.71496599 0.71496599\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.71071429 0.71088435 0.71088435\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.70255102 0.71088435 0.71088435\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.66496599 0.67746599 0.67746599\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.64022109 0.66496599 0.66079932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.64022109 0.66904762 0.66904762\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.60739796 0.62372449 0.64829932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.62397959 0.62397959 0.63579932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.58707483 0.58707483 0.63579932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.5662415  0.5662415  0.63579932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.55382653 0.55382653 0.63579932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.55382653 0.55382653 0.63579932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.5497449  0.5497449  0.63579932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.5497449  0.5497449  0.63579932\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551\n",
      " 0.47108844        nan        nan 0.5497449  0.5497449  0.61972789\n",
      "        nan        nan        nan        nan 0.80986395 0.82627551]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1e-10, class_weight=balanced, max_iter=100, multi_class=ovr, penalty=None, solver=newton-cg;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e+14, 3.23745754e+13, 1.04811313e+13, 3.39322177e+12,\n",
       "       1.09854114e+12, 3.55648031e+11, 1.15139540e+11, 3.72759372e+10,\n",
       "       1.20679264e+10, 3.90693994e+09, 1.26485522e+09, 4.09491506e+08,\n",
       "       1.32571137e+08, 4.29193426e+07, 1.38949549e+07, 4.49843267e+06,\n",
       "       1.45634848e+06, 4.71486636e+05, 1.526417...\n",
       "       2.32995181e-04, 7.54312006e-05, 2.44205309e-05, 7.90604321e-06,\n",
       "       2.55954792e-06, 8.28642773e-07, 2.68269580e-07, 8.68511374e-08,\n",
       "       2.81176870e-08, 9.10298178e-09, 2.94705170e-09, 9.54095476e-10,\n",
       "       3.08884360e-10, 1.00000000e-10]),\n",
       "                         &#x27;class_weight&#x27;: [&#x27;balanced&#x27;], &#x27;max_iter&#x27;: [100],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;ovr&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e+14, 3.23745754e+13, 1.04811313e+13, 3.39322177e+12,\n",
       "       1.09854114e+12, 3.55648031e+11, 1.15139540e+11, 3.72759372e+10,\n",
       "       1.20679264e+10, 3.90693994e+09, 1.26485522e+09, 4.09491506e+08,\n",
       "       1.32571137e+08, 4.29193426e+07, 1.38949549e+07, 4.49843267e+06,\n",
       "       1.45634848e+06, 4.71486636e+05, 1.526417...\n",
       "       2.32995181e-04, 7.54312006e-05, 2.44205309e-05, 7.90604321e-06,\n",
       "       2.55954792e-06, 8.28642773e-07, 2.68269580e-07, 8.68511374e-08,\n",
       "       2.81176870e-08, 9.10298178e-09, 2.94705170e-09, 9.54095476e-10,\n",
       "       3.08884360e-10, 1.00000000e-10]),\n",
       "                         &#x27;class_weight&#x27;: [&#x27;balanced&#x27;], &#x27;max_iter&#x27;: [100],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;ovr&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e+14, 3.23745754e+13, 1.04811313e+13, 3.39322177e+12,\n",
       "       1.09854114e+12, 3.55648031e+11, 1.15139540e+11, 3.72759372e+10,\n",
       "       1.20679264e+10, 3.90693994e+09, 1.26485522e+09, 4.09491506e+08,\n",
       "       1.32571137e+08, 4.29193426e+07, 1.38949549e+07, 4.49843267e+06,\n",
       "       1.45634848e+06, 4.71486636e+05, 1.526417...\n",
       "       2.32995181e-04, 7.54312006e-05, 2.44205309e-05, 7.90604321e-06,\n",
       "       2.55954792e-06, 8.28642773e-07, 2.68269580e-07, 8.68511374e-08,\n",
       "       2.81176870e-08, 9.10298178e-09, 2.94705170e-09, 9.54095476e-10,\n",
       "       3.08884360e-10, 1.00000000e-10]),\n",
       "                         'class_weight': ['balanced'], 'max_iter': [100],\n",
       "                         'multi_class': ['ovr'],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['liblinear', 'lbfgs', 'newton-cg']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different Values for Various Hyperparameters\n",
    "\n",
    "LogTune={\"C\" : np.logspace(10^4,10^-4) , \n",
    "         \"penalty\" : [\"l1\" , \"l2\" , \"elasticnet\" , None] , \n",
    "         \"solver\" : [\"liblinear\" , \"lbfgs\" , \"newton-cg\"] , \n",
    "         \"multi_class\" : [\"ovr\"] , \n",
    "         \"class_weight\" : [\"balanced\"] , \n",
    "         \"max_iter\" : [100]\n",
    "        }\n",
    "\n",
    "LogMod=GridSearchCV(LogisticRegression() , param_grid=LogTune , cv=5 , verbose=3)\n",
    "LogMod.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "764da01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.9306977288832536,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding Best Parameter\n",
    "\n",
    "LogMod.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e5f56d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data with Hyperparameter Tuning\n",
    "\n",
    "np.random.seed(30)\n",
    "model=LogisticRegression(C=1.9306977288832536 , class_weight=\"balanced\" , multi_class=\"ovr\" , max_iter=100, penalty=\"l2\" , solver=\"lbfgs\")\n",
    "model.fit(X_train , y_train)\n",
    "log_sco1=model.score(X_test , y_test)\n",
    "log_sco1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90200ecb",
   "metadata": {},
   "source": [
    "##### Logistic Regression - Baseline Parameters are Good ( 85.25% )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb4e88",
   "metadata": {},
   "source": [
    "#### 2 . Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd752e7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 240 is smaller than n_iter=2000. Running 240 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.917 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.917 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.729 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.917 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.729 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.917 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.854 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.729 total time=   0.6s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.875 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.896 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.708 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.917 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.854 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.854 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.729 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.917 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.917 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.854 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.917 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.854 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.750 total time=   0.9s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.653 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.875 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.479 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.755 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.708 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.917 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.854 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.729 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.854 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.729 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.854 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.917 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.854 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.729 total time=   0.6s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.755 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.755 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.917 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.917 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.854 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.917 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.854 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.729 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.917 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.917 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.729 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.917 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.854 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.729 total time=   0.6s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.633 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.479 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.521 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.521 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.604 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.875 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.896 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.771 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.837 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.857 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.875 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.896 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.857 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.896 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.875 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.771 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.857 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.875 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.875 total time=   2.7s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.750 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.878 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.857 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.875 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.896 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.750 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.896 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.896 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.750 total time=   3.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.612 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.673 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.490 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.667 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.837 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.837 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.875 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.896 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.771 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.878 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.837 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.875 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.896 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.771 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.875 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.896 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.792 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.837 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.837 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.875 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.896 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.750 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.837 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.875 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.896 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.750 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.875 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.896 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.729 total time=   2.3s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.896 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.729 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.646 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.646 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.837 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.837 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.875 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.896 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.750 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.875 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.896 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.792 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.875 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.896 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.771 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.857 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.837 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.875 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.875 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.837 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.917 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.875 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.750 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.896 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.896 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.750 total time=   2.5s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.604 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.551 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.896 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.551 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.688 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.837 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.896 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.896 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.792 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.837 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.896 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.896 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.875 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.896 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.729 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.857 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.896 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.896 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.750 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.816 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.857 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.875 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.896 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.750 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.796 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.875 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.896 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.750 total time=   2.5s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.735 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.646 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.917 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.792 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.646 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.812 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.708 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.771 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.776 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.612 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.792 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.792 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.771 total time=   4.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.673 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.673 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.812 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.729 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.771 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.633 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.694 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.604 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.792 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.750 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.714 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.633 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.542 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.812 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.708 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.551 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.776 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.833 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.771 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.771 total time=   4.2s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.551 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.857 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.531 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.667 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.673 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.551 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.500 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.708 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.729 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.755 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.583 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.792 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.604 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.796 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.708 total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.792 total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.750 total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.714 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.592 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.500 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.771 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.750 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.735 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.796 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.750 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.708 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.688 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.776 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.667 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.792 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.750 total time=   4.3s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.562 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.735 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.604 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.646 total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.694 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.604 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.755 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.562 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.792 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.771 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.735 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.562 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.854 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.750 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.776 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.755 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.875 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.771 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.500 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.694 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.612 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.854 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.625 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.708 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.551 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.490 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.625 total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.833 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.604 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.592 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.708 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.792 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.708 total time=   3.6s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.917 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.490 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.688 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.796 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.771 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.750 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.729 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.592 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.776 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.688 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.833 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.667 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.571 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.571 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.708 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.812 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.688 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.837 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.776 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.812 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.771 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.667 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.796 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.735 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.812 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.812 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.729 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.735 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.816 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.854 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.792 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.708 total time=   4.2s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.755 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.562 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.469 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.667 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.612 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.604 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.776 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.776 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.542 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.750 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.708 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.531 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.776 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.458 total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.812 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.750 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.673 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.755 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.875 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.792 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.479 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.551 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.857 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.917 total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.812 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.646 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.857 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.796 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.750 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.875 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.562 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.571 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.592 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.583 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.812 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.583 total time=   4.3s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.735 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.562 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.729 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.796 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.796 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.625 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.792 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.708 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.857 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.592 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.646 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.792 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.708 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.571 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.857 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.792 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.812 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.688 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.837 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.837 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.917 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.750 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.688 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.755 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.776 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.583 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.562 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.729 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.571 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.735 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.833 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.812 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.729 total time=   3.6s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.653 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.667 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.755 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.776 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.875 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.812 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.792 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.857 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.796 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.458 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.653 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.500 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.708 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.750 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.592 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.796 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.583 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.708 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.551 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.776 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.625 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.854 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.708 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.633 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.735 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.458 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.583 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.479 total time=   4.2s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.500 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.755 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.694 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.938 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.812 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.667 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.776 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.796 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.875 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.625 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.562 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.776 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.673 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.854 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.812 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.708 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.837 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.792 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.833 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.571 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.653 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.833 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.833 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.521 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.694 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.812 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.792 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.729 total time=   4.3s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.604 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.583 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.708 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.694 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.694 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.792 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.729 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.708 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.776 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.612 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.771 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.771 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.837 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.833 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.729 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.729 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.816 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.755 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.583 total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.667 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.571 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.776 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.750 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.854 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.667 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.633 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.735 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.542 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.688 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.708 total time=   4.1s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.551 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.917 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.646 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.837 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.816 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.458 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.812 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.750 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.857 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.653 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.458 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.583 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.729 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.673 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.776 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.771 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.792 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.771 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.531 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.694 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.583 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.750 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.735 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.755 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.792 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.854 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.812 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.531 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.776 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.896 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.583 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.771 total time=   3.8s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.510 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.469 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.792 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.479 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.667 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.458 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.583 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.708 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.796 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.796 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.771 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.750 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.688 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.816 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.714 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.750 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.854 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.562 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.755 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.816 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.812 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.750 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.500 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.510 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.776 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.688 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.771 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.729 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.694 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.633 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.458 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.792 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.688 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.837 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.551 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.833 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.771 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=1000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.750 total time=   4.8s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l1, tol=0.01;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.646 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.0001;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.571 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.583 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.001;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.735 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.646 total time=   0.0s\n",
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=ovr, penalty=l2, tol=0.01;, score=0.500 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.837 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.612 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.896 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.583 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.0001;, score=0.646 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.694 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.776 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.708 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.854 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.001;, score=0.708 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.633 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.796 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.500 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.792 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l1, tol=0.01;, score=0.521 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.653 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.776 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.562 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.812 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.0001;, score=0.708 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.571 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.633 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.625 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.792 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.001;, score=0.729 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.714 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.755 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.604 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.812 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "300 fits failed out of a total of 1200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 315, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 315, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.78503401 0.77278912 0.77278912\n",
      " 0.82653061 0.82653061 0.82653061 0.82653061 0.82653061 0.82653061\n",
      "        nan        nan        nan 0.80569728 0.81003401 0.79362245\n",
      " 0.82653061 0.82653061 0.82653061 0.82653061 0.82653061 0.83069728\n",
      "        nan        nan        nan 0.72338435 0.72278912 0.80187075\n",
      " 0.82653061 0.82653061 0.82653061 0.82653061 0.82653061 0.82653061\n",
      "        nan        nan        nan 0.76054422 0.81428571 0.78903061\n",
      " 0.82653061 0.82653061 0.82653061 0.82653061 0.82653061 0.82653061\n",
      "        nan        nan        nan 0.65246599 0.73486395 0.80620748\n",
      " 0.83486395 0.83877551 0.84710884 0.83469388 0.85110544 0.84302721\n",
      "        nan        nan        nan 0.74047619 0.71164966 0.81811224\n",
      " 0.84302721 0.85119048 0.84719388 0.83886054 0.83477891 0.83469388\n",
      "        nan        nan        nan 0.74855442 0.76403061 0.70314626\n",
      " 0.83886054 0.83903061 0.84302721 0.83460884 0.83894558 0.84302721\n",
      "        nan        nan        nan 0.68494898 0.76088435 0.64991497\n",
      " 0.84727891 0.83477891 0.83469388 0.84302721 0.83886054 0.83069728\n",
      "        nan        nan        nan 0.69370748 0.81862245 0.76445578\n",
      " 0.78486395 0.74838435 0.73188776 0.69447279 0.68188776 0.74030612\n",
      "        nan        nan        nan 0.74022109 0.74727891 0.67372449\n",
      " 0.63239796 0.71011905 0.77244898 0.66539116 0.73528912 0.76003401\n",
      "        nan        nan        nan 0.75144558 0.66879252 0.74804422\n",
      " 0.73928571 0.74353741 0.73528912 0.69872449 0.62066327 0.72738095\n",
      "        nan        nan        nan 0.80603741 0.80603741 0.69906463\n",
      " 0.77244898 0.71096939 0.6702381  0.77244898 0.77695578 0.78103741\n",
      "        nan        nan        nan 0.71420068 0.68647959 0.69005102\n",
      " 0.71020408 0.66539116 0.71488095 0.75663265 0.76811224 0.62848639\n",
      "        nan        nan        nan 0.80960884 0.72687075 0.79328231\n",
      " 0.74336735 0.71896259 0.74404762 0.80552721 0.68112245 0.73622449\n",
      "        nan        nan        nan 0.73112245 0.71045918 0.73571429\n",
      " 0.80195578 0.71394558 0.68962585 0.68171769 0.70280612 0.57763605\n",
      "        nan        nan        nan 0.81819728 0.81394558 0.67210884\n",
      " 0.77312925 0.72678571 0.76479592 0.80144558 0.68239796 0.77278912\n",
      "        nan        nan        nan 0.71045918 0.76845238 0.73095238\n",
      " 0.72338435 0.73171769 0.78894558 0.71011905 0.72355442 0.66096939\n",
      "        nan        nan        nan 0.74047619 0.77244898 0.76028912\n",
      " 0.73477891 0.65620748 0.75646259 0.65739796 0.78962585 0.71122449\n",
      "        nan        nan        nan 0.6042517  0.70578231 0.65204082\n",
      " 0.76003401 0.73945578 0.72678571 0.69464286 0.65280612 0.74838435\n",
      "        nan        nan        nan 0.72695578 0.65705782 0.69761905\n",
      " 0.71479592 0.74804422 0.64821429 0.70238095 0.66998299 0.69387755]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100.0, loss=squared_hinge, max_iter=2000, multi_class=crammer_singer, penalty=l2, tol=0.01;, score=0.583 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LinearSVC(), n_iter=2000,\n",
       "                   param_distributions={&#x27;C&#x27;: array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                                        &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;],\n",
       "                                        &#x27;max_iter&#x27;: [1000, 2000],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;ovr&#x27;,\n",
       "                                                        &#x27;crammer_singer&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01]},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LinearSVC(), n_iter=2000,\n",
       "                   param_distributions={&#x27;C&#x27;: array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                                        &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;],\n",
       "                                        &#x27;max_iter&#x27;: [1000, 2000],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;ovr&#x27;,\n",
       "                                                        &#x27;crammer_singer&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.001, 0.01]},\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LinearSVC(), n_iter=2000,\n",
       "                   param_distributions={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                                        'loss': ['hinge', 'squared_hinge'],\n",
       "                                        'max_iter': [1000, 2000],\n",
       "                                        'multi_class': ['ovr',\n",
       "                                                        'crammer_singer'],\n",
       "                                        'penalty': ['l1', 'l2'],\n",
       "                                        'tol': [0.0001, 0.001, 0.01]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different Values for Various Hyperparameters\n",
    "\n",
    "LinTune={\"C\" : np.logspace(-2,2,5) , \n",
    "         \"penalty\" : [\"l1\" , \"l2\"] , \n",
    "         \"loss\" : [\"hinge\" , \"squared_hinge\"] , \n",
    "         \"tol\" : [1e-4 , 1e-3 , 1e-2] ,\n",
    "         \"max_iter\" : [1000,2000] ,\n",
    "         \"multi_class\" : [\"ovr\" , \"crammer_singer\"]\n",
    "        }\n",
    "\n",
    "LinMod=RandomizedSearchCV(LinearSVC() , param_distributions=LinTune , cv=5 , verbose=3 , n_iter=2000)\n",
    "LinMod.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9a8face",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 0.001,\n",
       " 'penalty': 'l1',\n",
       " 'multi_class': 'crammer_singer',\n",
       " 'max_iter': 2000,\n",
       " 'loss': 'hinge',\n",
       " 'C': 0.1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding Best Parameter\n",
    "\n",
    "LinMod.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75abed61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.819672131147541"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data with Hyperparameter Tuning\n",
    "\n",
    "np.random.seed(30)\n",
    "model=LinearSVC(C=0.1  , loss=\"hinge\" , max_iter=2000 , multi_class=\"crammer_singer\" , penalty=\"l1\" , tol=0.001)\n",
    "model.fit(X_train , y_train)\n",
    "lin_sco1=model.score(X_test , y_test)\n",
    "lin_sco1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d529c85-4c60-4d72-b0d6-6999e214376d",
   "metadata": {},
   "source": [
    "##### Linear SVC - Tuned Hyperparameters are Good ( 81.96% )\n",
    "\n",
    "* C = 0.1\n",
    "* loss = hinge\n",
    "*  max_iter =2000\n",
    "*  multi_class = crammer_singer\n",
    "*  penalty = l1\n",
    "*  tot = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d908d",
   "metadata": {},
   "source": [
    "#### 3 . Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e33c8350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.837 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   2.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.875 total time=   2.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.9s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.878 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.9s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.9s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.9s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.9s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.896 total time=   2.5s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.837 total time=   0.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.854 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.854 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.854 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.854 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.857 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.735 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.735 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.9s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.875 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.735 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.9s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.857 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.750 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.875 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.857 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.917 total time=   2.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.714 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.771 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.735 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.875 total time=   2.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.771 total time=   2.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.735 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.854 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.735 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.938 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.857 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.776 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.9s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.9s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.875 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.938 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.837 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.735 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.4s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.857 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.9s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.792 total time=   2.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.854 total time=   1.9s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.938 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.875 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.938 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.857 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.771 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.875 total time=   1.9s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.878 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.735 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.735 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.771 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.875 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.9s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   2.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.917 total time=   2.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   2.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.878 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.4s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.9s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.9s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.854 total time=   1.9s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.854 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.735 total time=   1.9s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.9s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.9s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.857 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.735 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.875 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.771 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.735 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.875 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.735 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.750 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.837 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.735 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.875 total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.735 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.837 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.735 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.857 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.735 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.9s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.714 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.771 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.837 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.771 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.735 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.735 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.735 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.735 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.9s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.714 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.735 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.938 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.837 total time=   2.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.776 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.875 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.896 total time=   2.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.735 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.878 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.854 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.771 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.776 total time=   1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.875 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.735 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.771 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.771 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.771 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.854 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.938 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.9s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.9s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.875 total time=   1.9s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.875 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.9s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.837 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.938 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.735 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.735 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.857 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.854 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.857 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.857 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.9s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.771 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.857 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.771 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.750 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.837 total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.837 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.771 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.875 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.938 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.837 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.938 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.735 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.735 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.938 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.750 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.7s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.735 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.875 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.938 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.857 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.714 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.771 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.735 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.735 total time=   0.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.938 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.771 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.714 total time=   1.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.938 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.735 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.714 total time=   1.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.896 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.735 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.938 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.854 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.735 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.854 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.958 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.875 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.837 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.8s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.714 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.776 total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.8s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.875 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.755 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.938 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.9s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.837 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.7s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.8s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.917 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.816 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.735 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.792 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.735 total time=   0.8s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.9s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.9s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   1.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.816 total time=   2.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.771 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.875 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.792 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.776 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.8s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.854 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.854 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.792 total time=   0.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.771 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.875 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.755 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.837 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.776 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.875 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.792 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.735 total time=   2.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.9s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.896 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.714 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.714 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.771 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.714 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.837 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.735 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.755 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.917 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.771 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.755 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.875 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.938 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.776 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.896 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.854 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.938 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.816 total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.796 total time=   1.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.833 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.796 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.837 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.776 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.917 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.854 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.857 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.796 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.837 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.714 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.917 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.714 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.917 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.837 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.714 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.917 total time=   1.5s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.735 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.875 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.816 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.755 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.896 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   0.5s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.796 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.917 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.812 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "810 fits failed out of a total of 2430.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\adars\\Desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.80603741 0.82653061 0.83069728\n",
      " 0.83894558 0.82670068 0.82253401 0.82244898 0.82244898 0.83494898\n",
      " 0.83069728 0.81420068 0.81836735 0.82661565 0.82261905 0.81836735\n",
      " 0.81420068 0.81011905 0.82244898 0.83078231 0.81836735 0.83078231\n",
      " 0.82227891 0.80603741 0.81003401 0.81428571 0.81011905 0.81836735\n",
      " 0.83911565 0.83477891 0.82670068 0.83503401 0.82253401 0.82244898\n",
      " 0.84319728 0.82244898 0.82670068 0.81853741 0.81836735 0.81811224\n",
      " 0.82661565 0.83086735 0.82653061 0.82653061 0.84328231 0.82653061\n",
      " 0.81828231 0.82653061 0.83061224 0.84311224 0.82661565 0.82244898\n",
      " 0.79778912 0.83903061 0.80170068        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.81845238 0.83477891 0.83494898 0.83903061 0.83494898 0.82244898\n",
      " 0.81836735 0.83069728 0.81411565 0.81428571 0.83486395 0.82261905\n",
      " 0.81853741 0.83078231 0.81836735 0.83894558 0.82653061 0.82653061\n",
      " 0.81836735 0.83078231 0.81420068 0.83078231 0.81836735 0.81828231\n",
      " 0.81811224 0.79770408 0.81428571 0.82670068 0.83477891 0.83903061\n",
      " 0.84719388 0.81845238 0.82661565 0.79761905 0.82244898 0.82244898\n",
      " 0.83903061 0.82661565 0.83486395 0.80595238 0.82661565 0.81853741\n",
      " 0.80603741 0.82653061 0.81828231 0.82244898 0.82653061 0.81836735\n",
      " 0.81853741 0.81836735 0.82661565 0.81420068 0.81011905 0.81819728\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.80612245 0.83086735 0.83494898\n",
      " 0.83477891 0.82661565 0.82670068 0.82670068 0.81819728 0.81828231\n",
      " 0.80620748 0.82678571 0.82661565 0.80603741 0.83069728 0.83069728\n",
      " 0.83494898 0.82661565 0.82253401 0.81836735 0.81811224 0.82236395\n",
      " 0.82253401 0.82661565 0.82661565 0.81411565 0.83078231 0.83069728\n",
      " 0.83494898 0.82687075 0.82661565 0.82253401 0.82653061 0.83494898\n",
      " 0.83503401 0.83095238 0.82244898 0.82653061 0.82253401 0.82670068\n",
      " 0.83877551 0.83494898 0.83069728 0.82678571 0.81420068 0.83078231\n",
      " 0.82661565 0.83894558 0.81828231 0.79753401 0.81420068 0.82244898\n",
      " 0.80994898 0.82670068 0.81420068        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83903061 0.81853741 0.81836735 0.81862245 0.82261905 0.82261905\n",
      " 0.82253401 0.82670068 0.82687075 0.82261905 0.82261905 0.83903061\n",
      " 0.81845238 0.83494898 0.82261905 0.82253401 0.82261905 0.82253401\n",
      " 0.81428571 0.81853741 0.81845238 0.81836735 0.81845238 0.82270408\n",
      " 0.82670068 0.81853741 0.82270408 0.80178571 0.82670068 0.81853741\n",
      " 0.81437075 0.82661565 0.82261905 0.83486395 0.81020408 0.83086735\n",
      " 0.80612245 0.82261905 0.82670068 0.83486395 0.82253401 0.82261905\n",
      " 0.83494898 0.84302721 0.82253401 0.81011905 0.82253401 0.80612245\n",
      " 0.81011905 0.81445578 0.82278912 0.81845238 0.81437075 0.81445578\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.82678571 0.81845238 0.83095238\n",
      " 0.82261905 0.82670068 0.83086735 0.83069728 0.80603741 0.83503401\n",
      " 0.81845238 0.83494898 0.83086735 0.81845238 0.82261905 0.81437075\n",
      " 0.83494898 0.82236395 0.82661565 0.82253401 0.81853741 0.81845238\n",
      " 0.81845238 0.82670068 0.83086735 0.82253401 0.81011905 0.82270408\n",
      " 0.82678571 0.82261905 0.81028912 0.80595238 0.82270408 0.82678571\n",
      " 0.82278912 0.83086735 0.83494898 0.81845238 0.83086735 0.83086735\n",
      " 0.83486395 0.83903061 0.83494898 0.84719388 0.82678571 0.83086735\n",
      " 0.83486395 0.82253401 0.82678571 0.81853741 0.81853741 0.81845238\n",
      " 0.80603741 0.81853741 0.82253401        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.81420068 0.81428571 0.82678571 0.82670068 0.81828231 0.82678571\n",
      " 0.81819728 0.81428571 0.82270408 0.82244898 0.83903061 0.82678571\n",
      " 0.81428571 0.83086735 0.83494898 0.81836735 0.81428571 0.82253401\n",
      " 0.81828231 0.82270408 0.81028912 0.81445578 0.81028912 0.81037415\n",
      " 0.82253401 0.83078231 0.81853741 0.82670068 0.81437075 0.81020408\n",
      " 0.84328231 0.81428571 0.82670068 0.84328231 0.83086735 0.83086735\n",
      " 0.82687075 0.82270408 0.82670068 0.81437075 0.82670068 0.83494898\n",
      " 0.81853741 0.83494898 0.81420068 0.82670068 0.83477891 0.81853741\n",
      " 0.81445578 0.82261905 0.81853741 0.81437075 0.82261905 0.82261905]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 500]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 500]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [10, 20, None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 500]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different Values for Various Hyperparameters\n",
    "\n",
    "RanTune={'n_estimators': [100, 200, 500],\n",
    "         'max_depth': [10, 20, None],\n",
    "         'min_samples_split': [2, 5, 10],\n",
    "         'min_samples_leaf': [1, 2, 4],\n",
    "         'max_features': ['auto', 'sqrt', 'log2'],\n",
    "         'bootstrap': [True, False]\n",
    "        }\n",
    "\n",
    "RanMod=GridSearchCV(RandomForestClassifier() , param_grid=RanTune , cv=5 , verbose=3)\n",
    "RanMod.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e40b9e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 20,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding Best Parameter\n",
    "\n",
    "RanMod.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aee6d91f-5260-4db5-a175-8f1dd60496c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing Data with Hyperparameter Tuning\n",
    "\n",
    "np.random.seed(30)\n",
    "model=RandomForestClassifier(n_estimators=100 , min_samples_split=5 , min_samples_leaf=1 , max_features=\"log2\" , max_depth=20 , bootstrap=True)\n",
    "model.fit(X_train , y_train)\n",
    "rfc_sco1=model.score(X_test , y_test)\n",
    "rfc_sco1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760b2ad-b479-4c02-9257-fbf1108ef6f0",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier - Tuned Hyperparameters are Good ( 85.24% )\n",
    "* n_estimators = 100\n",
    "* min_samples_split = 5\n",
    "* min_samples_leaf = 1\n",
    "* max_features = \"log2\"\n",
    "* max_depth = 20\n",
    "* bootstrap = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
